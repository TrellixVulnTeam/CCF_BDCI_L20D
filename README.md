# 0.前言

去年10月、11月的时候参加了DataFountain的面向数据安全治理的数据内容智能发现与分级分类比赛https://www.datafountain.cn/competitions/471，最终获得了A榜第24、B榜第24的成绩。在这里记录一下此次比赛历程。

。

# 1.赛题背景

随着企业信息化水平的不断提高，数据共享与开放对企业发展的作用日益凸显，数据已成为重要生产要素之一，企业在产业与服务、营销支持、业务运营、风险管控、信息披露和分析决策等经营管理活动中涉及到大量的业务数据，其中可能会包含企业的商业秘密、工作秘密，以及员工的隐私信息等，若因为使用不当，造成数据泄露，则有可能造成巨大的经济损失，或在社会、法律、信用、品牌上对企业造成严重的不良影响。同时，在合规要求层面，围绕数据安全，国家近年密集颁布《网络安全法》、《民法典》、《数据安全法》（征求意见稿）、《个人信息保护法》（征求意见稿）等，从国家法律层面强调对关键基础设施、各类APP应用中的敏感数据保护要求。而为了有效、规范保护企业敏感数据，其首要问题是对数据进行分级分类，以识别敏感数据，从而进一步围绕保护对象的全生命周期进行开放、动态的数据安全治理，解决数据开放共享与数据隐私保护的矛盾与统一。
现有的敏感数据识别与分级分类已广泛采用基于自然语言处理的语义识别技术，但会存在以下问题：
1.需要有大批量、高质量的标注数据，花费大量的人力和时间，建设成本高。
2.泛化能力不足，对新业务数据的适应能力弱，敏感数据的误报率和漏报率高。
3.不能进行自我优化、自我学习，需要业务和技术领域专家共同进行人工干预，建设难度大。

# 2.赛题任务

识别样本中的敏感数据，构建基于敏感数据本体的分级分类模型，判断数据所属的类别以及级别。
1.利用远程监督技术，基于小样本构建文档分类分级样本库。
2.结合当下先进的深度学习和机器学习技术，利用已构建的样本库，提取文本语义特征，构建泛化能力强且能自我学习的文档分类分级模型。

# 3.数据简介与说明

（1）已标注数据：共7000篇文档，类别包含7类，分别为：财经、房产、家居、教育、科技、时尚、时政，每一类包含1000篇文档。
（2）未标注数据：共33000篇文档。
（3）分类分级测试数据：共20000篇文档，包含10个类别:财经、房产、家居、教育、科技、时尚、时政、游戏、娱乐、体育。

本次大赛提供两份数据，已标注数据labeled_data.csv，未标注数据 unlabeled_data.csv，分类分级测试数据test_data.csv。
（1）已标注数据 labeled_data.csv

|  字段信息   |  类型  |     描述     |
| :---------: | :----: | :----------: |
|     id      | String |    数据ID    |
| class_label | String | 文本所属类别 |
|   content   | String |   文本内容   |

（2）未标注数据unlabeled_data.csv

| 字段信息 |  类型  |   描述   |
| :------: | :----: | :------: |
|    id    | String |  数据ID  |
| content  | String | 文本内容 |

（3）分类分级测试数据 test_data.csv

| 字段信息 |  类型  |   描述   |
| :------: | :----: | :------: |
|    id    | String |  数据ID  |
| content  | String | 文本内容 |

（4）分级信息
假设文档类别与文档级别有如下对应关系：

|     文档类别     | 文档级别 |
| :--------------: | :------: |
|    财经、时政    |  高风险  |
|    房产、科技    |  中风险  |
| 教育、时尚、游戏 |  低风险  |
| 家居、体育、娱乐 |  可公开  |

**本次比赛不允许使用外部数据集~**

可以简单的理解为，此次比赛是一个文本分类问题；但是给的训练集有7类数据，测试集有10类数据，需要事先在未标注数据（共33000篇文档）中采用无监督的方法选取标签为另外3类的部分数据，加入到训练集中训练。

# 4.无监督文本分类

由于本次提供的训练集共7000篇文档，类别包含7类；首先需要在unlabled数据集中采用无监督的方法将另外3类（游戏、娱乐、体育）分出来；

本文采用了LDA文本聚类算法，首先通过该算法将未标注33000篇文档聚为10类，然后从类别为游戏、娱乐、体育的数据中各随机出1000条，与原始数据组成10000条的训练集。



# 5.其他trick

1. EDA文本增强技术（https://github.com/jasonwei20/eda_nlp）（无提升）。

2. 采用半监督的思想，对测试集预测，并将预测结果与原有数据一起训练（无提升）。

3. F1值优化(效果不稳定)

4. 使用THUCnews进行模型预训练（后因主办方不允许使用外部数据放弃），单纯使用部分THUCnews做为训练集训练，对测试集进行预测得分只有0.5+。

   预训练参考（https://github.com/zhusleep/pytorch_chinese_lm_pretrain）

   


